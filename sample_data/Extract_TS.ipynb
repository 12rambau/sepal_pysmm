{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, HBox\n",
    "\n",
    "from osgeo import gdal\n",
    "from stackcomposed.stack_composed import parse as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Extracted_coordinates_sipalaga_site_phu_number.csv', delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data with the phu number\n",
    "data = data[data.ID == 1109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Notes for usage\n",
    "    \n",
    "    This script is not well optimized. For each given point it will read each image and \n",
    "    will extract the pixel value. This is because from a small instance there is not enough\n",
    "    memory to store a stack of images.\n",
    "    \n",
    "    All the images must have the same date name format, because the script will sort the list\n",
    "    according its date.\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob.glob('/home/dguerrero/pysmm_downloads/1_processed/ReducedAreas_107PHU/1109/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files.sort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal_file_extent = gdal.Open(image_files[0], gdal.GA_ReadOnly)# Assumming all images have the same extent\n",
    "\n",
    "\n",
    "def read_images():\n",
    "    gdal_file = gdal.Open(image_files[0], gdal.GA_ReadOnly)\n",
    "    nodata_from_file = gdal_file.GetRasterBand(1).GetNoDataValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raster(raster_path):\n",
    "    gdal_file = gdal.Open(raster_path, gdal.GA_ReadOnly)\n",
    "    raster_band = gdal_file.GetRasterBand(1).ReadAsArray()\n",
    "    raster_band = raster_band.astype(np.float32)\n",
    "    return raster_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sm(x, y):\n",
    "    \n",
    "    \"\"\" This function will create a dictionary with the extracted dates \n",
    "        for each image as key and the extracted value with the read_raster function\n",
    "        as value. Then the result will be transformed as pandas df replacing the 0 values\n",
    "        as numpy no data value.\n",
    "    \"\"\"\n",
    "    ts_dict = {pd.to_datetime(pc.parse_other_files(image)[4]):read_raster(image)[x][y] for image in image_files}\n",
    "    \n",
    "    ts_df = pd.DataFrame(ts_dict.values(), index=ts_dict.keys())\n",
    "    ts_df = ts_df.replace(0, np.nan)\n",
    "    \n",
    "    return ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_xy(gdal_file_extent):\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions explores the image extent and retrieve the position\n",
    "    of a given coordinates in row-col type.\n",
    "    \"\"\"\n",
    "    \n",
    "    min_x, x_res, x_skew, max_y, y_skew, y_res = gdal_file_extent.GetGeoTransform()\n",
    "    \n",
    "    for index, row in data.iterrows(): \n",
    "\n",
    "        lon=float(row['longitude'])\n",
    "        lat=float(row['latitude'])\n",
    "        \n",
    "        #column in pixel coordinates\n",
    "        column = int(((max_y - lat) / x_res) + 1)\n",
    "\n",
    "        #row in pixel coordinates\n",
    "        row = int(((lon - min_x) / x_res) + 1)\n",
    "        \n",
    "        data.at[index,'row'] = row\n",
    "        data.at[index,'column'] = column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_xy(gdal_file_extent) # Create Rows and columns based on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['ts_data'] = None\n",
    "\n",
    "pbar = tqdm(total = len(data), desc=\"Retrieving...\")\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    x = int(row['column'])\n",
    "    y = int(row['row'])\n",
    "    \n",
    "    pbar.desc =f\"Retrieving for {x}, {y}...\"\n",
    "    \n",
    "    if x > 0 and y > 0:\n",
    "        ts_df = get_sm(x, y)\n",
    "        data.at[index, 'ts_data'] = ts_df\n",
    "    \n",
    "    pbar.update(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('data/pysmm_ts_SIPAGALA_points_2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
